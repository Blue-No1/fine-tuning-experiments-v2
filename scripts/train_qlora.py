# Like train_lora.py but load model with bitsandbytes 8-bit and use r=16
# (Pseudo-change to signal QLoRA; code omitted for brevity in this snippet)
print("QLoRA skeleton â€” see configs/qlora-llama3-8b.yaml")
